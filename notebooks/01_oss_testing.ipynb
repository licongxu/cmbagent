{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "## CMBAgent - OSS Testing\n",
    "\n",
    "*For testing purposes only, to be removed before opening a PR to* `main` ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local model testing supported via https://github.com/acceleratescience/mini-vllm (private Accelerate repo)\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "BASE_URL = os.getenv(\"LOCAL_LLM_BASE_URL\")\n",
    "API_KEY = os.getenv(\"LOCAL_LLM_API_KEY\")\n",
    "\n",
    "local_llm_config = {\n",
    "    \"config_list\": [\n",
    "        {\n",
    "            \"model\": \"openai/gpt-oss-20b\", # Must match model id from endpoint\n",
    "            \"api_key\": API_KEY,\n",
    "            \"api_type\": \"openai\",\n",
    "            \"base_url\": BASE_URL,\n",
    "            \"price\": [0.0, 0.0], # Passed explicitly to ignore warning\n",
    "        },\n",
    "    ],\n",
    "    \"cache_seed\": None\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "### AG2 ConversableAgent() with `openai/gpt-oss-20b`\n",
    "\n",
    "Simple chat with a tiny model (`openai/gpt-oss-20b`)to verify ConversableAgent() has OSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33magent\u001b[0m (to user):\n",
      "\n",
      "What is the meaning of Denario?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33muser\u001b[0m (to agent):\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "             Model agent    Cost  Prompt Tokens  Completion Tokens  Total Tokens\n",
      "openai/gpt-oss-20b agent 0.00000             86                312           398\n",
      "\u001b[33magent\u001b[0m (to user):\n",
      "\n",
      "*Denario* is the Latin word for a Roman silver coin that entered use in 211â€¯BC, worth 10 asses. Its name comes from the Latin â€œdenarius,â€ itself derived from a unit of weight, and in modern Romance languages the word (and its cognates) still means â€œmoneyâ€ or â€œcoin.â€\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33muser\u001b[0m (to agent):\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> TERMINATING RUN (fbd17823-fc2b-4f15-a978-ab0b3c69f06a): Maximum turns (2) reached\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ChatResult(chat_id=142075004582337632179642004039302304976, chat_history=[{'content': 'What is the meaning of Denario?', 'role': 'assistant', 'name': 'agent'}, {'content': '', 'role': 'user', 'name': 'user'}, {'content': '*Denario* is the Latin word for a Roman silver coin that entered use in 211\\u202fBC, worth 10 asses. Its name comes from the Latin â€œdenarius,â€ itself derived from a unit of weight, and in modern Romance languages the word (and its cognates) still means â€œmoneyâ€ or â€œcoin.â€', 'role': 'assistant', 'name': 'agent'}, {'content': '', 'role': 'user', 'name': 'user'}], summary='', cost={'usage_including_cached_inference': {'total_cost': 0.0, 'openai/gpt-oss-20b': {'cost': 0.0, 'prompt_tokens': 86, 'completion_tokens': 312, 'total_tokens': 398}}, 'usage_excluding_cached_inference': {'total_cost': 0.0, 'openai/gpt-oss-20b': {'cost': 0.0, 'prompt_tokens': 86, 'completion_tokens': 312, 'total_tokens': 398}}}, human_input=[])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from autogen import UserProxyAgent, ConversableAgent\n",
    "\n",
    "# Creates the agent that uses the vLLM LM\n",
    "assistant = ConversableAgent(\n",
    "    \"agent\",\n",
    "    llm_config=local_llm_config,\n",
    "    system_message=\"Answer briefly.\",\n",
    ")\n",
    "\n",
    "# Create the agent that represents the user in the conversation\n",
    "user_proxy = UserProxyAgent(\n",
    "    \"user\",\n",
    "    code_execution_config=False,\n",
    "    system_message=\"\",\n",
    "    human_input_mode=\"NEVER\",\n",
    ")\n",
    "\n",
    "# User asks a question\n",
    "assistant.initiate_chat(\n",
    "    user_proxy,\n",
    "    message=\"What is the meaning of Denario?\",\n",
    "    max_turns=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "### AG2 ConversableAgent() Tool Calling with OSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33magent\u001b[0m (to agent):\n",
      "\n",
      "Use the add tool to add 2 and 3. Then reply with just the number.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "             Model agent    Cost  Prompt Tokens  Completion Tokens  Total Tokens\n",
      "openai/gpt-oss-20b agent 0.00000            175                 39           214\n",
      "\u001b[33magent\u001b[0m (to agent):\n",
      "\n",
      "\u001b[32m***** Suggested tool call (chatcmpl-tool-b17d29ad9f94de4a): add *****\u001b[0m\n",
      "Arguments: \n",
      "{\"a\": 2, \"b\": 3}\n",
      "\u001b[32m*********************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[35m\n",
      ">>>>>>>> EXECUTING FUNCTION add...\n",
      "Call ID: chatcmpl-tool-b17d29ad9f94de4a\n",
      "Input arguments: {'a': 2, 'b': 3}\u001b[0m\n",
      "\u001b[35m\n",
      ">>>>>>>> EXECUTED FUNCTION add...\n",
      "Call ID: chatcmpl-tool-b17d29ad9f94de4a\n",
      "Input arguments: {'a': 2, 'b': 3}\n",
      "Output:\n",
      "5.0\u001b[0m\n",
      "\u001b[33magent\u001b[0m (to agent):\n",
      "\n",
      "\u001b[32m***** Response from calling Tool tool (chatcmpl-tool-b17d29ad9f94de4a) *****\u001b[0m\n",
      "5.0\n",
      "\u001b[32m****************************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "             Model agent    Cost  Prompt Tokens  Completion Tokens  Total Tokens\n",
      "openai/gpt-oss-20b agent 0.00000            426                 44           470\n",
      "\u001b[33magent\u001b[0m (to agent):\n",
      "\n",
      "5\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "             Model agent    Cost  Prompt Tokens  Completion Tokens  Total Tokens\n",
      "openai/gpt-oss-20b agent 0.00000            689                100           789\n",
      "\u001b[33magent\u001b[0m (to agent):\n",
      "\n",
      "Got it!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "             Model agent    Cost  Prompt Tokens  Completion Tokens  Total Tokens\n",
      "openai/gpt-oss-20b agent 0.00000            968                139          1107\n",
      "\u001b[33magent\u001b[0m (to agent):\n",
      "\n",
      "ðŸ‘\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> TERMINATING RUN (4b7eb614-9928-4a9f-ac60-7eb6a4168d81): Maximum turns (3) reached\u001b[0m\n",
      "[{'id': 'chatcmpl-tool-b17d29ad9f94de4a', 'function': {'arguments': '{\"a\": 2, \"b\": 3}', 'name': 'add'}, 'type': 'function'}]\n",
      "[{'id': 'chatcmpl-tool-b17d29ad9f94de4a', 'function': {'arguments': '{\"a\": 2, \"b\": 3}', 'name': 'add'}, 'type': 'function'}]\n"
     ]
    }
   ],
   "source": [
    "def add(a: float, b: float) -> float:\n",
    "    return a + b\n",
    "\n",
    "assistant.register_for_llm(name=\"add\", description=\"Add two numbers\")(add)\n",
    "assistant.register_for_execution(name=\"add\")(add)\n",
    "\n",
    "result = assistant.initiate_chat(\n",
    "    recipient=assistant,\n",
    "    message=\"Use the add tool to add 2 and 3. Then reply with just the number.\",\n",
    "    max_turns=3,\n",
    ")\n",
    "\n",
    "for msg in result.chat_history:\n",
    "    if msg.get(\"tool_calls\"):\n",
    "        print(msg[\"tool_calls\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "### OSS with Engineer Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OSS] Defaulted formatter model to openai/gpt-oss-20b\n",
      "\u001b[33m_User\u001b[0m (to main_cmbagent_chat):\n",
      "\n",
      "\n",
      "Plot the graph of y = x from x = 0 to 1\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: engineer\n",
      "\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "             Model    agent    Cost  Prompt Tokens  Completion Tokens  Total Tokens\n",
      "openai/gpt-oss-20b engineer 0.00000           1768               1540          3308\n",
      "\u001b[33mengineer\u001b[0m (to main_cmbagent_chat):\n",
      "\n",
      "**Code Explanation:**\n",
      "\n",
      "The script creates a plot of the function y = x over the interval [0, 1]. It generates 100 evenly spaced points, plots the line, labels the axes, adds a title and grid, and saves the figure as a highâ€‘resolution PNG file in the `data/` directory. The filename includes a timestamp to ensure uniqueness. The script prints a concise message indicating where the plot was saved.\n",
      "\n",
      "**Modifications:** None.\n",
      "\n",
      "**Python Code:**\n",
      "\n",
      "```python\n",
      "import os\n",
      "import datetime\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "plt.rcParams['text.usetex'] = False\n",
      "\n",
      "def main():\n",
      "    \"\"\"Plot y = x from 0 to 1 and save the figure to the data folder.\"\"\"\n",
      "    os.makedirs('data', exist_ok=True)\n",
      "    x = np.linspace(0, 1, 100)\n",
      "    y = x\n",
      "    fig, ax = plt.subplots()\n",
      "    ax.plot(x, y)\n",
      "    ax.set_xlabel('x')\n",
      "    ax.set_ylabel('y')\n",
      "    ax.set_title('Plot of y = x')\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "    ts = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')\n",
      "    filename = 'plot_y_equals_x_1_' + ts + '.png'\n",
      "    filepath = os.path.join('data', filename)\n",
      "    plt.savefig(filepath, dpi=300)\n",
      "    print('Plot saved to ' + filepath)\n",
      "\n",
      "if __name__ == '__main__':\n",
      "    main()\n",
      "```\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[34m***** AfterWork handoff (engineer): engineer_nest *****\u001b[0m\n",
      "\u001b[32m\n",
      "Next speaker: engineer_nest\n",
      "\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[34m\n",
      "********************************************************************************\u001b[0m\n",
      "\u001b[34mStarting a new chat....\u001b[0m\n",
      "\u001b[34m\n",
      "********************************************************************************\u001b[0m\n",
      "\u001b[33mengineer_nest\u001b[0m (to engineer_nested_chat):\n",
      "\n",
      "**Code Explanation:**\n",
      "\n",
      "The script creates a plot of the function y = x over the interval [0, 1]. It generates 100 evenly spaced points, plots the line, labels the axes, adds a title and grid, and saves the figure as a highâ€‘resolution PNG file in the `data/` directory. The filename includes a timestamp to ensure uniqueness. The script prints a concise message indicating where the plot was saved.\n",
      "\n",
      "**Modifications:** None.\n",
      "\n",
      "**Python Code:**\n",
      "\n",
      "```python\n",
      "import os\n",
      "import datetime\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "plt.rcParams['text.usetex'] = False\n",
      "\n",
      "def main():\n",
      "    \"\"\"Plot y = x from 0 to 1 and save the figure to the data folder.\"\"\"\n",
      "    os.makedirs('data', exist_ok=True)\n",
      "    x = np.linspace(0, 1, 100)\n",
      "    y = x\n",
      "    fig, ax = plt.subplots()\n",
      "    ax.plot(x, y)\n",
      "    ax.set_xlabel('x')\n",
      "    ax.set_ylabel('y')\n",
      "    ax.set_title('Plot of y = x')\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "    ts = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')\n",
      "    filename = 'plot_y_equals_x_1_' + ts + '.png'\n",
      "    filepath = os.path.join('data', filename)\n",
      "    plt.savefig(filepath, dpi=300)\n",
      "    print('Plot saved to ' + filepath)\n",
      "\n",
      "if __name__ == '__main__':\n",
      "    main()\n",
      "```\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: engineer_response_formatter\n",
      "\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "             Model                       agent    Cost  Prompt Tokens  Completion Tokens  Total Tokens\n",
      "openai/gpt-oss-20b engineer_response_formatter 0.00000           1152                719          1871\n",
      "\u001b[33mengineer_response_formatter\u001b[0m (to engineer_nested_chat):\n",
      "\n",
      "{\"filename\":\"step_1.py\",\"relative_path\":null,\"code_explanation\":\"The script creates a plot of the function y = x over the interval [0, 1]. It generates 100 evenly spaced points, plots the line, labels the axes, adds a title and grid, and saves the figure as a highâ€‘resolution PNG file in the `data/` directory. The filename includes a timestamp to ensure uniqueness. The script prints a concise message indicating where the plot was saved.\",\"modification_summary\":null,\"python_code\":\"import os\\nimport datetime\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\n\\nplt.rcParams['text.usetex'] = False\\n\\ndef main():\\n    \\\"\\\"\\\"Plot y = x from 0 to 1 and save the figure to the data folder.\\\"\\\"\\\"\\n    os.makedirs('data', exist_ok=True)\\n    x = np.linspace(0, 1, 100)\\n    y = x\\n    fig, ax = plt.subplots()\\n    ax.plot(x, y)\\n    ax.set_xlabel('x')\\n    ax.set_ylabel('y')\\n    ax.set_title('Plot of y = x')\\n    ax.grid(True)\\n    plt.tight_layout()\\n    ts = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')\\n    filename = 'plot_y_equals_x_1_' + ts + '.png'\\n    filepath = os.path.join('data', filename)\\n    plt.savefig(filepath, dpi=300)\\n    print('Plot saved to ' + filepath)\\n\\nif __name__ == '__main__':\\n    main()\\n\"}\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: executor\n",
      "\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> EXECUTING CODE BLOCK (inferred language is python)...\u001b[0m\n",
      "\n",
      " code being executed....\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/fingriffin/PycharmProjects/cmbagent/notebooks/one_shot/step_1.py\", line 5, in <module>\n",
      "    import matplotlib.pyplot as plt\n",
      "ModuleNotFoundError: No module named 'matplotlib'\n",
      "\n",
      "\n",
      "\u001b[33mexecutor\u001b[0m (to engineer_nested_chat):\n",
      "\n",
      "execution results:\n",
      "Execution output: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/fingriffin/PycharmProjects/cmbagent/notebooks/one_shot/step_1.py\", line 5, in <module>\n",
      "    import matplotlib.pyplot as plt\n",
      "ModuleNotFoundError: No module named 'matplotlib'\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> TERMINATING RUN (9590489a-0869-41b7-a5cf-08187d6403ef): Maximum rounds (3) reached\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> TERMINATING RUN (9b17b35b-446a-4a5a-814e-c040b0befa18): Maximum turns (1) reached\u001b[0m\n",
      "\u001b[33mengineer_nest\u001b[0m (to main_cmbagent_chat):\n",
      "\n",
      "\n",
      "The executed code was:\n",
      "\n",
      "```python\n",
      "\n",
      "```\n",
      "\n",
      "================================================    \n",
      "\n",
      "The output of the executed code was:\n",
      "\n",
      "execution results:\n",
      "Execution output: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/fingriffin/PycharmProjects/cmbagent/notebooks/one_shot/step_1.py\", line 5, in <module>\n",
      "    import matplotlib.pyplot as plt\n",
      "ModuleNotFoundError: No module named 'matplotlib'\n",
      "\n",
      "\n",
      "================================================    \n",
      "                        \n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[34m***** AfterWork handoff (engineer_nest): executor_response_formatter *****\u001b[0m\n",
      "\u001b[32m\n",
      "Next speaker: executor_response_formatter\n",
      "\u001b[0m\n",
      "\u001b[33mRemoved 2 messages. Number of messages reduced from 3 to 1.\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "             Model                       agent    Cost  Prompt Tokens  Completion Tokens  Total Tokens\n",
      "openai/gpt-oss-20b executor_response_formatter 0.00000            523                 86           609\n",
      "\u001b[33mexecutor_response_formatter\u001b[0m (to main_cmbagent_chat):\n",
      "\n",
      "\u001b[32m***** Suggested tool call (chatcmpl-tool-aa0191990eb6f7c9): post_execution_transfer *****\u001b[0m\n",
      "Arguments: \n",
      "{\"next_agent_suggestion\": \"installer\", \"execution_status\": \"failure\", \"fix_suggestion\": \"Install matplotlib using pip (e.g., pip install matplotlib).\"}\n",
      "\u001b[32m*****************************************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: _Group_Tool_Executor\n",
      "\u001b[0m\n",
      "\u001b[35m\n",
      ">>>>>>>> EXECUTING FUNCTION post_execution_transfer...\n",
      "Call ID: chatcmpl-tool-aa0191990eb6f7c9\n",
      "Input arguments: {'next_agent_suggestion': 'installer', 'execution_status': 'failure', 'fix_suggestion': 'Install matplotlib using pip (e.g., pip install matplotlib).'}\u001b[0m\n",
      "\u001b[35m\n",
      ">>>>>>>> EXECUTED FUNCTION post_execution_transfer...\n",
      "Call ID: chatcmpl-tool-aa0191990eb6f7c9\n",
      "Input arguments: {'next_agent_suggestion': 'installer', 'execution_status': 'failure', 'fix_suggestion': 'Install matplotlib using pip (e.g., pip install matplotlib).'}\n",
      "Output:\n",
      "Execution status: failure. Transfer to installer.\n",
      "\n",
      "xxxxxxxxxxxxxxxxxxxxxxxxxx\n",
      "\n",
      "Workflow status:\n",
      "\n",
      "Plan step number: 1\n",
      "\n",
      "Agent for sub-task (might be different from the next agent suggestion for debugging): engineer\n",
      "\n",
      "Current status (before execution): In progress\n",
      "\n",
      "xxxxxxxxxxxxxxxxxxxxxxxxxx\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34m***** ReplyResult transition (executor_response_formatter): installer *****\u001b[0m\n",
      "\u001b[33m_Group_Tool_Executor\u001b[0m (to main_cmbagent_chat):\n",
      "\n",
      "\u001b[32m***** Response from calling Tool tool (chatcmpl-tool-aa0191990eb6f7c9) *****\u001b[0m\n",
      "Execution status: failure. Transfer to installer.\n",
      "\n",
      "xxxxxxxxxxxxxxxxxxxxxxxxxx\n",
      "\n",
      "Workflow status:\n",
      "\n",
      "Plan step number: 1\n",
      "\n",
      "Agent for sub-task (might be different from the next agent suggestion for debugging): engineer\n",
      "\n",
      "Current status (before execution): In progress\n",
      "\n",
      "xxxxxxxxxxxxxxxxxxxxxxxxxx\n",
      "\n",
      "\n",
      "\u001b[32m****************************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> TERMINATING RUN (b549b305-91d3-47f9-8526-9c3e19cf58a5): Maximum rounds (5) reached\u001b[0m\n",
      "\n",
      "Displaying costâ€¦\n",
      "\n",
      "| Agent                       | Cost ($)    | Prompt Tokens | Completion Tokens | Total Tokens | Model              |\n",
      "|:----------------------------|------------:|--------------:|------------------:|-------------:|-------------------:|\n",
      "| executor response formatter | $0.00000000 |           523 |                86 |          609 | openai/gpt-oss-20b |\n",
      "| engineer response formatter | $0.00000000 |          1152 |               719 |         1871 | openai/gpt-oss-20b |\n",
      "| engineer                    | $0.00000000 |          1768 |              1540 |         3308 | openai/gpt-oss-20b |\n",
      "|-----------------------------|-------------|---------------|-------------------|--------------|--------------------|\n",
      "| Total                       | $0.00000000 |          3443 |              2345 |         5788 |                    |\n",
      "\n",
      "Cost report data saved to: /Users/fingriffin/PycharmProjects/cmbagent/notebooks/one_shot/cost/cost_report_20260204_142942.json\n",
      "\n",
      "\n",
      "Timing report saved to /Users/fingriffin/PycharmProjects/cmbagent/notebooks/one_shot/time/timing_report_20260204_142942.json\n",
      "\n",
      "Task took 65.3393 seconds\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from cmbagent.workflows import one_shot\n",
    "\n",
    "local_engineer_config = local_llm_config[\"config_list\"][0]\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "tmp_path = Path.cwd()\n",
    "\n",
    "task = \"\"\"\n",
    "Plot the graph of y = x from x = 0 to 1\n",
    "\"\"\"\n",
    "\n",
    "results = one_shot(\n",
    "    task,\n",
    "\n",
    "    max_rounds=5,\n",
    "    agent=\"engineer\",\n",
    "    engineer_model=local_engineer_config,\n",
    "    work_dir=str(tmp_path / \"one_shot\"),\n",
    ")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
